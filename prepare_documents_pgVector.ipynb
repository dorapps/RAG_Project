{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import time\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pdf files in the local directory\n",
    "def load_and_split_text(pdf_path):\n",
    "    loader = PyPDFDirectoryLoader(pdf_path)\n",
    "\n",
    "    # docs_before_split = loader.load()\n",
    "\n",
    "\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(\n",
    "    #     chunk_size = 512,\n",
    "    #     chunk_overlap  = 100,\n",
    "    # )\n",
    "    # docs_after_split = text_splitter.split_documents(docs_before_split)\n",
    "\n",
    "    # return docs_after_split\n",
    "    doc_pages = loader.load()\n",
    "    return doc_pages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_substring_index(text, start_marker, end_marker):\n",
    "    start_index = text.index(start_marker) + len(start_marker)\n",
    "    end_index = text.index(end_marker, start_index)\n",
    "    return text[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_metadata(text):\n",
    "    AMBITO ='Ámbito Geográfico'\n",
    "    INFORMACION='Información Detallada'\n",
    "    AMBITO_CLEAN='AmbitoGeografico'\n",
    "\n",
    "    document_tags = ['Referencia','Organismo','Sector','Subsector',\n",
    "                    AMBITO,'Tipo','Destinatarios','Plazo de solicitud']\n",
    "\n",
    "    tagIndex = 0\n",
    "    metadata = {}\n",
    "\n",
    "    while tagIndex < len(document_tags)-1:\n",
    "        start = document_tags[tagIndex]\n",
    "        end = document_tags[tagIndex+1]\n",
    "        if(start=='Ámbito Geográfico'):\n",
    "            metadata[AMBITO_CLEAN]=extract_substring_index(text,start,end).replace(AMBITO,'').replace(INFORMACION,'').strip()\n",
    "        else:\n",
    "            metadata[start]=extract_substring_index(text,start,end).strip()\n",
    "        #metadataInText = metadataInText+\", \"+start+\" es \"+metadata[start]\n",
    "        tagIndex+=1\n",
    "            \n",
    "        \n",
    "    #return [ metadata, metadataInText ]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import requests\n",
    "def download_file(url,output_path,filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:        \n",
    "        with open(output_path+\"/\"+filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "def download_linked_files(page, output_path):\n",
    "    urls=[]\n",
    "    if \"/Annots\" in page:\n",
    "        for annot in page[\"/Annots\"]:\n",
    "            annotObj = annot.get_object()\n",
    "            if(\"/A\" in annotObj):\n",
    "                uri = annotObj.get(\"/A\").get(\"/URI\")\n",
    "                if uri is not None:\n",
    "                    print(\"[+] URL Found:\", uri)\n",
    "                    urls.append(uri)\n",
    "    \n",
    "    if(not os.path.exists(output_path)):\n",
    "        os.makedirs(output_path)\n",
    "    for url in urls:\n",
    "        download_file(url, output_path, str(uuid4())+\".pdf\")             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"jaimevera1107/all-MiniLM-L6-v2-similarity-es\",\n",
    "    #model_name=\"jinaai/jina-embeddings-v2-base-es\",\n",
    "    model_kwargs={'device':'cpu', 'trust_remote_code': True}, \n",
    "    encode_kwargs={'normalize_embeddings': False, 'attn_implementation': \"eager\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def remove_foler(folder):\n",
    "    try:\n",
    "        shutil.rmtree(folder)\n",
    "    except FileNotFoundError as e:                        \n",
    "        print('The folder does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_foler('./ayudas/texto/Guia de Ayudas Sector Comercio.pdf')\n",
    "#remove_foler('./db_subvenciones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"postgresql://postgres:postgres@localhost:5432/db_subvenciones\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=71572&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=71572&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=71572&fichero=\n",
      "Downloaded 9c20e330-c256-4c11-a38f-b221c6484f2c.pdf\n",
      "Downloaded 12847bb2-592a-4570-af29-e019349fc5da.pdf\n",
      "Downloaded 94bf6e90-20aa-4f52-a3fe-51ae50d0e789.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=111733&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=111733&fichero=\n",
      "Downloaded cd7e8253-e4d6-4d95-93e6-2e5ef716c28a.pdf\n",
      "Downloaded ee7a27e8-e354-47cb-87e0-5f6d79837c56.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=112431&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=112431&fichero=\n",
      "Downloaded f0022e86-4c26-4301-aadc-3300fd20a210.pdf\n",
      "Downloaded c501bb78-c9f3-4c9b-bfc9-a60ca6cb40c9.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=113986&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=113986&fichero=\n",
      "Downloaded 5df51911-34cb-4c21-aa6c-bd30a21c88af.pdf\n",
      "Downloaded 5a95306d-24c1-4d89-87c2-e9c753d8bed4.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=114535&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=114535&fichero=\n",
      "Downloaded f43dc314-f03b-4610-a8b4-21ccb4ec2fa7.pdf\n",
      "Downloaded cad34152-7bd0-4ac1-a75b-2068dcd8112d.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115300&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115300&fichero=\n",
      "Downloaded 01486826-04f7-48dd-8048-51061130cbbf.pdf\n",
      "Downloaded 81e7db87-36b3-4176-ad4f-d2ddab452784.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115472&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115472&fichero=\n",
      "Downloaded 69cf3de8-f494-4063-8ce6-172a172283b1.pdf\n",
      "Downloaded 47dc80b1-1a38-48d7-9d37-24ad11350279.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115656&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115656&fichero=\n",
      "Downloaded a1d52163-6ba2-4977-b1b7-6416273c8df1.pdf\n",
      "Downloaded ad84cb56-ff03-4385-b55b-b901b09565c3.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115771&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115771&fichero=\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=115771&fichero=\n",
      "Downloaded 57f8db7e-84b5-4cac-bfa5-3e0d7bdccf9f.pdf\n",
      "Downloaded c45a2209-0f48-4329-b2ba-c693cf4f5296.pdf\n",
      "Downloaded 76ef7c45-be25-463b-97cc-cca03915fc6d.pdf\n",
      "[+] URL Found: https://wapis.ipyme.org/servicioayudas/ayudas/detalle?id=116081&fichero=\n",
      "Downloaded 24149dec-c16a-4104-b128-d020411195ce.pdf\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import chromadb\n",
    "from chromadbx import UUIDGenerator\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "\n",
    "# Cargar modelo de embedding\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Crear una colección en ChromaDB\n",
    "\n",
    "pathToMetadata = './ayudas/metadatos'\n",
    "pathToText = './ayudas/texto'\n",
    "\n",
    "# Función para procesar un PDF\n",
    "def process_pdf(pdf_path):\n",
    "    all_pages = []\n",
    "    limit=0\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)        \n",
    "        for page_num in range(len(reader.pages)):\n",
    "            if limit == 10:\n",
    "                break\n",
    "            summary_page = reader.pages[page_num]\n",
    "            text = summary_page.extract_text().replace(\"\\n\",\" \")\n",
    "            \n",
    "            if (text.find(\"Ayudas e incentivos (detalle)\") > -1):\n",
    "                a = urlparse(pdf_path)\n",
    "                output_dir = pathToText+\"/\"+os.path.basename(a.path)+\"/\"+\"Page_\"+str(page_num)\n",
    "                \n",
    "                #Get metadata from page\n",
    "                \"\"\"  metadata = get_metadata(text)\n",
    "                page_metadata = metadata[0]\n",
    "                page_metadataInText = metadata[1] \"\"\"\n",
    "                \n",
    "                extra_metadata = get_metadata(text)\n",
    "                download_linked_files(summary_page, output_dir)\n",
    "    \n",
    "                pages = load_and_split_text(output_dir)\n",
    "                \n",
    "                if(len(pages) > 0):\n",
    "\n",
    "\n",
    "                    for page in pages:\n",
    "                        page.metadata = page.metadata = {**page.metadata, **extra_metadata}\n",
    "                all_pages=all_pages+pages\n",
    "                limit+=1\n",
    "    return all_pages            \n",
    "\n",
    "# Procesar todos los PDFs en una carpeta\n",
    "import os\n",
    "limit = 1\n",
    "allDocs = []\n",
    "\n",
    "for file in os.listdir(pathToMetadata):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        docs = process_pdf(os.path.join(pathToMetadata, file))\n",
    "        allDocs= allDocs+docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = PGVector.from_documents(allDocs, embedding=huggingface_embeddings,connection=connection_string,collection_name=\"subvenciones\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "# Perform a similarity search\n",
    "query = \"Extracto de la Resolución de 12 de noviembre de 2019\"\n",
    "results = db.similarity_search(query)\n",
    "\n",
    "pprint.pp(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
